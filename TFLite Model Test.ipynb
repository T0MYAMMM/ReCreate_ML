{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55403,"status":"ok","timestamp":1686154204100,"user":{"displayName":"Gabriel Kaka","userId":"04787379389972578085"},"user_tz":-420},"id":"8Nuy6CZJmBGU","outputId":"148bd201-7e00-4a06-a3bb-e7eece3d088a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.8.0\n","  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py\u003e=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (23.3.3)\n","Requirement already satisfied: gast\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.4.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n","Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.8.0)\n","Collecting keras-preprocessing\u003e=1.1.1 (from tensorflow==2.8.0)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang\u003e=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (16.0.0)\n","Requirement already satisfied: numpy\u003e=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.22.4)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.3.0)\n","Requirement already satisfied: protobuf\u003e=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (67.7.2)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.3.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.5.0)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.14.1)\n","Collecting tensorboard\u003c2.9,\u003e=2.8 (from tensorflow==2.8.0)\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras\u003c2.9,\u003e=2.8.0rc0 (from tensorflow==2.8.0)\n","  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.32.0)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.54.0)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow==2.8.0) (0.40.0)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (2.17.3)\n","Collecting google-auth-oauthlib\u003c0.5,\u003e=0.4.1 (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (3.4.3)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (2.27.1)\n","Collecting tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (1.8.1)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (2.3.0)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (5.3.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (0.3.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (1.3.1)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (1.26.15)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (2.0.12)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (3.4)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug\u003e=0.11.15-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (2.1.2)\n","Requirement already satisfied: pyasn1\u003c0.6.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (0.5.0)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow==2.8.0) (3.2.2)\n","Installing collected packages: tf-estimator-nightly, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.0\n","    Uninstalling tensorboard-data-server-0.7.0:\n","      Successfully uninstalled tensorboard-data-server-0.7.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","Successfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"]}],"source":["!pip install tensorflow==2.8.0\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTeM-tP0mPAQ"},"outputs":[],"source":["# Script to run custom TFLite model on test images to detect objects\n","# Source: https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/TFLite_detection_image.py\n","\n","# Import packages\n","import os\n","import cv2\n","import numpy as np\n","import sys\n","import glob\n","import random\n","import importlib.util\n","from tensorflow.lite.python.interpreter import Interpreter\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","### Define function for inferencing with TFLite model and displaying results\n","\n","def tflite_detect_images(modelpath, imgpath, lblpath, min_conf=0.5, num_test_images=10, savepath='/content/results', txt_only=False):\n","\n","  # Grab filenames of all images in test folder\n","  images = glob.glob(imgpath + '/*.jpg') + glob.glob(imgpath + '/*.JPG') + glob.glob(imgpath + '/*.png') + glob.glob(imgpath + '/*.bmp')\n","\n","  # Load the label map into memory\n","  with open(lblpath, 'r') as f:\n","      labels = [line.strip() for line in f.readlines()]\n","\n","  # Load the Tensorflow Lite model into memory\n","  interpreter = Interpreter(model_path=modelpath)\n","  interpreter.allocate_tensors()\n","\n","  # Get model details\n","  input_details = interpreter.get_input_details()\n","  print(input_details)\n","  output_details = interpreter.get_output_details()\n","  height = input_details[0]['shape'][1]\n","  width = input_details[0]['shape'][2]\n","\n","  float_input = (input_details[0]['dtype'] == np.float32)\n","  print(\"FPN = \",float_input)\n","  input_mean = 127.5\n","  input_std = 127.5\n","\n","  # Randomly select test images\n","  images_to_test = random.sample(images, num_test_images)\n","\n","  # Loop over every image and perform detection\n","  for image_path in images_to_test:\n","\n","      # Load image and resize to expected shape [1xHxWx3]\n","      image = cv2.imread(image_path)\n","      image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      imH, imW, _ = image.shape \n","      image_resized = cv2.resize(image_rgb, (width, height))\n","      input_data = np.expand_dims(image_resized, axis=0)\n","\n","      # Normalize pixel values if using a floating model (i.e. if model is non-quantized)\n","      if float_input:\n","          input_data = (np.float32(input_data) - input_mean) / input_std\n","\n","      # Perform the actual detection by running the model with the image as input\n","      interpreter.set_tensor(input_details[0]['index'],input_data)\n","      interpreter.invoke()\n","\n","      # Retrieve detection results\n","      boxes = interpreter.get_tensor(output_details[1]['index'])[0] # Bounding box coordinates of detected objects\n","      classes = interpreter.get_tensor(output_details[3]['index'])[0] # Class index of detected objects\n","      scores = interpreter.get_tensor(output_details[0]['index'])[0] # Confidence of detected objects\n","\n","      detections = []\n","\n","      # Loop over all detections and draw detection box if confidence is above minimum threshold\n","      for i in range(len(scores)):\n","          if ((scores[i] \u003e min_conf) and (scores[i] \u003c= 1.0)):\n","\n","              # Get bounding box coordinates and draw box\n","              # Interpreter can return coordinates that are outside of image dimensions, need to force them to be within image using max() and min()\n","              ymin = int(max(1,(boxes[i][0] * imH)))\n","              xmin = int(max(1,(boxes[i][1] * imW)))\n","              ymax = int(min(imH,(boxes[i][2] * imH)))\n","              xmax = int(min(imW,(boxes[i][3] * imW)))\n","              \n","              cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (10, 255, 0), 2)\n","\n","              # Draw label\n","              object_name = labels[int(classes[i])] # Look up object name from \"labels\" array using class index\n","              label = '%s: %d%%' % (object_name, int(scores[i]*100)) # Example: 'person: 72%'\n","              labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2) # Get font size\n","              label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n","              cv2.rectangle(image, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), (255, 255, 255), cv2.FILLED) # Draw white box to put label text in\n","              cv2.putText(image, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2) # Draw label text\n","\n","              detections.append([object_name, scores[i], xmin, ymin, xmax, ymax])\n","\n","      \n","      # All the results have been drawn on the image, now display the image\n","      if txt_only == False: # \"text_only\" controls whether we want to display the image results or just save them in .txt files\n","        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n","        plt.figure(figsize=(12,16))\n","        plt.imshow(image)\n","        plt.show()\n","      \n","      # Save detection results in .txt files (for calculating mAP)\n","      elif txt_only == True:\n","\n","        # Get filenames and paths\n","        image_fn = os.path.basename(image_path)      \n","        base_fn, ext = os.path.splitext(image_fn)\n","        txt_result_fn = base_fn +'.txt'\n","        txt_savepath = os.path.join(savepath, txt_result_fn)\n","\n","        # Write results to text file\n","        # (Using format defined by https://github.com/Cartucho/mAP, which will make it easy to calculate mAP)\n","        with open(txt_savepath,'w') as f:\n","            for detection in detections:\n","                f.write('%s %.4f %d %d %d %d\\n' % (detection[0], detection[1], detection[2], detection[3], detection[4], detection[5]))\n","\n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wYVVlTljww0iusJIFXL8FJvXPwisjmYY"},"id":"FpHhmIxdmwea","outputId":"5ea32507-509b-4650-afcc-db37d7b722de"},"outputs":[],"source":["# Set up variables for running user's model\n","PATH_TO_IMAGES='/content/images/test'   # Path to test images folder\n","PATH_TO_MODEL='/content/detect_meta_2.tflite'   # Path to .tflite model file\n","PATH_TO_LABELS='/content/label_map.txt'   # Path to labelmap.txt file\n","min_conf_threshold=0.5   # Confidence threshold (try changing this to 0.01 if you don't see any detection results)\n","images_to_test = 8  # Number of images to run detection on\n","\n","# Run inferencing function!\n","tflite_detect_images(PATH_TO_MODEL, PATH_TO_IMAGES, PATH_TO_LABELS, min_conf_threshold, images_to_test)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMcUpb+zz2cMhOSBpNACs3u","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}